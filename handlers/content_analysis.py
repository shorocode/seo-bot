from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, ParseMode
from telegram.ext import CallbackContext, MessageHandler, Filters, CallbackQueryHandler
from collections import Counter
from typing import Dict, List, Optional, Tuple
import re
import logging

from services.ai import AIService
from services.database import Database
from utils.decorators import log_activity, restricted
from utils.helpers import truncate_text, format_number
from utils.logger import logger

class ContentAnalysisHandler:
    def __init__(self, db: Database):
        self.db = db
        self.ai = AIService(api_key=settings.OPENAI_API_KEY)
        self.MAX_INPUT_LENGTH = 5000
        self.PERSIAN_STOPWORDS = self._load_persian_stopwords()

        self.TOOLS = [
            {
                'id': 'kw_density',
                'name': 'ğŸ“Š Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ',
                'description': 'ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ùˆ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ù…ØªÙ†',
                'input_prompt': 'ğŸ”  Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
                'min_words': 20,
                'handler': self.kw_density_handler
            },
            {
                'id': 'readability',
                'name': 'ğŸ“– ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ',
                'description': 'Ø³Ù†Ø¬Ø´ Ø³Ø·Ø­ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ù…ØªÙ† Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯',
                'input_prompt': 'ğŸ“š Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
                'min_words': 50,
                'handler': self.readability_handler
            },
            {
                'id': 'seo_analysis',
                'name': 'ğŸ” ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ',
                'description': 'Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªÙ† Ø§Ø² Ù†Ø¸Ø± Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø³Ø¦Ùˆ',
                'input_prompt': 'âœï¸ Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
                'min_words': 100,
                'handler': self.seo_analysis_handler
            }
        ]

    def _load_persian_stopwords(self) -> List[str]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÛŒØ³Øª Ú©Ù„Ù…Ø§Øª Ø¨ÛŒâ€ŒÙ…Ø¹Ù†ÛŒ ÙØ§Ø±Ø³ÛŒ"""
        return [
            'Ùˆ', 'Ø¯Ø±', 'Ø¨Ù‡', 'Ø§Ø²', 'Ú©Ù‡', 'Ø±Ø§', 'Ø§ÛŒÙ†', 'Ø§Ø³Øª', 'Ø¨Ø§', 'Ø¨Ø±Ø§ÛŒ',
            'Ø¢Ù†', 'ÛŒÚ©', 'ÛŒØ§', 'Ù‡Ù…', 'Ø§Ù…Ø§', 'ØªØ§', 'Ú©Ù†ÛŒØ¯', 'Ø´Ø¯Ù‡', 'Ø´ÙˆØ¯',
            'Ù‡Ø§ÛŒ', 'Ú©Ø±Ø¯', 'Ø´Ø¯', 'Ø®ÙˆØ¯', 'Ù…Ø§', 'Ø´Ù…Ø§', 'Ø§Ùˆ', 'Ø¢Ù†Ù‡Ø§', 'Ù‡Ù…Ù‡',
            'Ù‡Ø±', 'Ø§Ú¯Ø±', 'Ù†ÛŒØ²', 'Ø¯ÛŒÚ¯Ø±', 'Ø¨Ø³ÛŒØ§Ø±', 'Ú†Ù‡', 'Ù‡Ø³ØªÙ†Ø¯', 'Ø¨ÛŒ', 'Ù…Ù†',
            'ØªÙˆ', 'Ø¨Ø±', 'Ù‡Ù…ÛŒÙ†', 'Ù‡ÛŒÚ†', 'Ø¯Ùˆ', 'Ú†ÙˆÙ†', 'Ù¾ÛŒØ´', 'Ø¨ÛŒÙ†', 'Ú†ÛŒØ³Øª',
            'Ú©Ø±Ø¯Ù†', 'Ú©Ø±Ø¯Ù…', 'Ú©Ù†Ù…', 'Ú©Ù†ÛŒ', 'Ú©Ù†Ø¯', 'Ú©Ù†ÛŒÙ…', 'Ú©Ù†ÛŒØ¯', 'Ú©Ù†Ù†Ø¯'
        ]

    def validate_text(self, text: str, min_words: int) -> Tuple[bool, str]:
        """
        Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        
        Args:
            text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
            min_words: Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
            
        Returns:
            tuple: (is_valid, error_message)
        """
        if not text.strip():
            return False, "âš ï¸ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª."
            
        if len(text) > self.MAX_INPUT_LENGTH:
            return False, f"âš ï¸ Ù…ØªÙ† Ø¨Ø³ÛŒØ§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª (Ø­Ø¯Ø§Ú©Ø«Ø± {self.MAX_INPUT_LENGTH} Ú©Ø§Ø±Ø§Ú©ØªØ±)"
            
        word_count = len(text.split())
        if word_count < min_words:
            return False, f"âš ï¸ Ù…ØªÙ† Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª (Ø­Ø¯Ø§Ù‚Ù„ {min_words} Ú©Ù„Ù…Ù‡ Ù†ÛŒØ§Ø² Ø§Ø³Øª)"
            
        return True, ""

    @log_activity
    def kw_density_handler(self, update: Update, context: CallbackContext, text: str) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ†
        is_valid, error_msg = self.validate_text(text, self.TOOLS[0]['min_words'])
        if not is_valid:
            return error_msg

        try:
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª
            words = [
                word.strip('.,!?()[]{}"\'').lower() 
                for word in re.findall(r'\b\w+\b', text) 
                if word.strip()
            ]
            
            word_count = len(words)
            keyword_counts = Counter(words)
            
            # ÙÛŒÙ„ØªØ± Ú©Ù„Ù…Ø§Øª Ø¨ÛŒâ€ŒÙ…Ø¹Ù†ÛŒ
            meaningful_words = {
                kw: count for kw, count in keyword_counts.items() 
                if kw not in self.PERSIAN_STOPWORDS and len(kw) > 2
            }
            
            if not meaningful_words:
                return "âš ï¸ Ù‡ÛŒÚ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
            
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
            report = [
                "ğŸ“Š *Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:*",
                f"ğŸ”  ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú©Ù„Ù…Ø§Øª: {word_count}",
                f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯: {len(meaningful_words)}",
                "\nğŸ† *Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±ØªØ±:*"
            ]
            
            for kw, count in Counter(meaningful_words).most_common(10):
                density = (count / word_count) * 100
                report.append(f"- {kw}: {count} Ø¨Ø§Ø± ({density:.2f}%)")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            self.db.save_content_analysis(
                user_id=update.effective_user.id,
                tool_id='kw_density',
                input_text=truncate_text(text, 500),
                result='\n'.join(report)
            )
            
            return '\n'.join(report)
            
        except Exception as e:
            logger.error(f"Error in kw_density analysis: {e}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ø±Ø® Ø¯Ø§Ø¯."

    @log_activity
    def readability_handler(self, update: Update, context: CallbackContext, text: str) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ù…ØªÙ†"""
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ†
        is_valid, error_msg = self.validate_text(text, self.TOOLS[1]['min_words'])
        if not is_valid:
            return error_msg

        try:
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
            analysis = self.ai.analyze_text(
                task="readability_analysis",
                text=text,
                language="fa"
            )
            
            if not analysis:
                return "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
            result = [
                "ğŸ“š *Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ:*",
                f"ğŸ”¹ Ø§Ù…ØªÛŒØ§Ø² Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ: {analysis.get('score', 0)}/100",
                f"ğŸ”¹ Ø³Ø·Ø­ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ: {analysis.get('recommended_level', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
                f"ğŸ”¹ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ø¬Ù…Ù„Ù‡: {analysis.get('avg_sentence_length', 0)} Ú©Ù„Ù…Ù‡",
                "\nğŸ“Œ *ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯:*",
                analysis.get('suggestions', 'Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.')
            ]
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            self.db.save_content_analysis(
                user_id=update.effective_user.id,
                tool_id='readability',
                input_text=truncate_text(text, 500),
                result='\n'.join(result)
            )
            
            return '\n'.join(result)
            
        except Exception as e:
            logger.error(f"Error in readability analysis: {e}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯."

    @log_activity
    def seo_analysis_handler(self, update: Update, context: CallbackContext, text: str) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ù…ØªÙ†"""
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ†
        is_valid, error_msg = self.validate_text(text, self.TOOLS[2]['min_words'])
        if not is_valid:
            return error_msg

        try:
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
            analysis = self.ai.analyze_text(
                task="seo_analysis",
                text=text,
                language="fa"
            )
            
            if not analysis:
                return "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
            result = [
                "ğŸ” *Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ:*",
                f"ğŸ”¹ Ø§Ù…ØªÛŒØ§Ø² Ø³Ø¦Ùˆ: {analysis.get('score', 0)}/100",
                "\nâœ… *Ù†Ù‚Ø§Ø· Ù‚ÙˆØª:*",
                analysis.get('strengths', 'Ù‡ÛŒÚ† Ù†Ù‚Ø·Ù‡ Ù‚ÙˆØª Ù…Ø´Ø®ØµÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.'),
                "\nâš ï¸ *Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù:*",
                analysis.get('weaknesses', 'Ù‡ÛŒÚ† Ù†Ù‚Ø·Ù‡ Ø¶Ø¹Ù Ù…Ø´Ø®ØµÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.'),
                "\nğŸ’¡ *Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯:*",
                analysis.get('recommendations', 'Ù‡ÛŒÚ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.')
            ]
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            self.db.save_content_analysis(
                user_id=update.effective_user.id,
                tool_id='seo_analysis',
                input_text=truncate_text(text, 500),
                result='\n'.join(result)
            )
            
            return '\n'.join(result)
            
        except Exception as e:
            logger.error(f"Error in SEO analysis: {e}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ø±Ø® Ø¯Ø§Ø¯."

    def send_analysis_result(self, update: Update, tool_name: str, result: str) -> None:
        """Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        try:
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø¨Ø¹Ø¯ÛŒ
            buttons = [
                [InlineKeyboardButton("ğŸ”„ ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯", callback_data="content_menu")],
                [get_back_button()]
            ]

            update.message.reply_text(
                text=f"*{tool_name}*\n\n{result}",
                reply_markup=InlineKeyboardMarkup(buttons),
                parse_mode=ParseMode.MARKDOWN,
                disable_web_page_preview=True
            )
            
        except Exception as e:
            logger.error(f"Error sending analysis result: {e}", exc_info=True)
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø±Ø® Ø¯Ø§Ø¯.")

    def setup_handlers(self, dispatcher):
        """ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§"""
        for tool in self.TOOLS:
            dispatcher.add_handler(MessageHandler(
                Filters.text & ~Filters.command,
                tool['handler'],
                pass_user_data=True
            ))
