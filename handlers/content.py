# handlers/content.py - Ù…Ø¯ÛŒØ±ÛŒØª ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§

import logging
import re
from typing import Dict, List, Optional, Tuple
from collections import Counter

from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    ParseMode
)
from telegram.ext import (
    CallbackContext,
    CallbackQueryHandler,
    CommandHandler,
    MessageHandler,
    Filters
)

from config import settings
from config.keyboards import get_back_button
from services.database import db
from services.ai import AIService
from utils.decorators import restricted, log_activity
from utils.helpers import format_number, truncate_text
from utils.logger import logger

class ContentAnalysisHandler:
    def __init__(self):
        self.ai_service = AIService(api_key=settings.OPENAI_API_KEY)
        self.MAX_INPUT_LENGTH = 5000  # Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ

    # Ù„ÛŒØ³Øª Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§
    TOOLS = [
        {
            'id': 'kw_density',
            'name': 'ğŸ“Š Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ',
            'description': 'ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ùˆ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± Ù…ØªÙ†',
            'input_prompt': 'ğŸ”  Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
            'min_length': 50
        },
        {
            'id': 'readability',
            'name': 'ğŸ“– ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ',
            'description': 'Ø³Ù†Ø¬Ø´ Ø³Ø·Ø­ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ù…ØªÙ† Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯',
            'input_prompt': 'ğŸ“š Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ (Ø­Ø¯Ø§Ù‚Ù„ 100 Ú©Ù„Ù…Ù‡):',
            'min_length': 100
        },
        {
            'id': 'seo_optimize',
            'name': 'ğŸ” Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø¦Ùˆ',
            'description': 'ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø¦Ùˆ Ø¨Ø±Ø§ÛŒ Ù…ØªÙ†',
            'input_prompt': 'âœï¸ Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
            'min_length': 150
        },
        {
            'id': 'content_summary',
            'name': 'ğŸ“ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§',
            'description': 'Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ØªÙ† Ø¨Ø§ Ø­ÙØ¸ Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ',
            'input_prompt': 'ğŸ“„ Ù„Ø·ÙØ§ Ù…ØªÙ† Ø¨Ù„Ù†Ø¯ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
            'min_length': 200
        },
        {
            'id': 'plagiarism_check',
            'name': 'ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ',
            'description': 'ØªØ´Ø®ÛŒØµ Ù…Ø´Ø§Ø¨Ù‡Øªâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± ÙˆØ¨',
            'input_prompt': 'ğŸ“‘ Ù„Ø·ÙØ§ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:',
            'min_length': 50
        }
    ]

    @restricted()
    def content_menu(self, update: Update, context: CallbackContext) -> None:
        """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§"""
        try:
            buttons = []
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø¯Ùˆ ØªØ§ÛŒÛŒ
            for i in range(0, len(self.TOOLS), 2):
                row = []
                for tool in self.TOOLS[i:i+2]:
                    row.append(
                        InlineKeyboardButton(
                            text=tool['name'],
                            callback_data=f"content_{tool['id']}"
                        )
                    )
                buttons.append(row)
            
            buttons.append([get_back_button()])

            update.message.reply_text(
                text="ğŸ“ *Ù…Ù†ÙˆÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§*\n\nÙ„Ø·ÙØ§ Ø§Ø¨Ø²Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                reply_markup=InlineKeyboardMarkup(buttons),
                parse_mode=ParseMode.MARKDOWN
            )

        except Exception as e:
            logger.error(f"Error in content_menu: {str(e)}", exc_info=True)
            self.send_error_message(update, "Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§")

    def handle_content_callback(self, update: Update, context: CallbackContext) -> None:
        """Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù†ÙˆÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§"""
        query = update.callback_query
        query.answer()

        try:
            action = query.data.split('_')[1]  # Ø¨Ø®Ø´ Ø¯ÙˆÙ… callback_data (Ù…Ø«Ù„ kw_density)
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§Ø¨Ø²Ø§Ø± Ù…Ø±Ø¨ÙˆØ·Ù‡
            tool = next((t for t in self.TOOLS if t['id'] == action), None)
            
            if tool:
                context.user_data['content_tool'] = tool
                query.edit_message_text(
                    text=tool['input_prompt'],
                    reply_markup=InlineKeyboardMarkup([[get_back_button("Ù„ØºÙˆ")]])
                )
            else:
                query.edit_message_text("âš ï¸ Ø§Ø¨Ø²Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        except Exception as e:
            logger.error(f"Error in content callback: {str(e)}", exc_info=True)
            query.edit_message_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯.")

    def process_content_input(self, update: Update, context: CallbackContext) -> None:
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„"""
        try:
            text = update.message.text.strip()
            tool = context.user_data.get('content_tool')
            
            if not tool or not text:
                update.message.reply_text("âš ï¸ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
                return

            # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø¯Ø§Ù‚Ù„ Ø·ÙˆÙ„ Ù…ØªÙ†
            if len(text.split()) < tool.get('min_length', 50):
                update.message.reply_text(
                    f"âš ï¸ Ù…ØªÙ† Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§ Ù…ØªÙ†ÛŒ Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ {tool['min_length']} Ú©Ù„Ù…Ù‡ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
                )
                return

            # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„ Ù…ØªÙ†
            if len(text) > self.MAX_INPUT_LENGTH:
                text = text[:self.MAX_INPUT_LENGTH]
                update.message.reply_text(
                    f"âš ï¸ Ù…ØªÙ† Ø´Ù…Ø§ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨ÙˆØ¯ Ùˆ ÙÙ‚Ø· {self.MAX_INPUT_LENGTH} Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ÙˆÙ„ Ø¢Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯."
                )

            update.message.reply_text(f"â³ Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ø§Ø¨Ø²Ø§Ø± {tool['name']}...")
            
            # Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø¨Ø²Ø§Ø±
            if tool['id'] == 'kw_density':
                result = self.analyze_keyword_density(update, text)
            elif tool['id'] == 'readability':
                result = self.analyze_readability(update, text)
            elif tool['id'] == 'seo_optimize':
                result = self.optimize_seo(update, text)
            elif tool['id'] == 'content_summary':
                result = self.summarize_content(update, text)
            elif tool['id'] == 'plagiarism_check':
                result = self.check_plagiarism(update, text)
            else:
                result = "âš ï¸ Ø§Ø¨Ø²Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯."

            # Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡
            self.send_analysis_result(update, tool['name'], result)

        except Exception as e:
            logger.error(f"Error processing content input: {str(e)}", exc_info=True)
            self.send_error_message(update, "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ†")

    @log_activity
    def analyze_keyword_density(self, update: Update, text: str) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
        try:
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†
            words = [
                word.strip('.,!?()[]{}"\'').lower() 
                for word in re.findall(r'\b\w+\b', text) 
                if word.strip()
            ]
            
            if not words or len(words) < 50:
                return "âš ï¸ Ù…ØªÙ† Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§ Ù…ØªÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯."
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ±Ø§ÙˆØ§Ù†ÛŒ Ú©Ù„Ù…Ø§Øª
            word_count = len(words)
            keyword_counts = Counter(words)
            
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ù„Ù…Ø§Øª Ø¨Ø§ Ù…Ø¹Ù†ÛŒ
            stopwords = self._get_persian_stopwords()
            meaningful_words = {
                kw: count for kw, count in keyword_counts.items() 
                if kw not in stopwords and len(kw) > 2
            }
            
            if not meaningful_words:
                return "âš ï¸ Ù‡ÛŒÚ† Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯."
            
            sorted_kws = sorted(
                meaningful_words.items(), 
                key=lambda x: x[1], 
                reverse=True
            )
            
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
            report = ["ğŸ“Š *Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:*\n"]
            report.append(f"ğŸ”  ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú©Ù„Ù…Ø§Øª: {word_count}")
            report.append(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯: {len(meaningful_words)}\n")
            report.append("ğŸ† *Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±ØªØ±:*")
            
            for kw, count in sorted_kws[:15]:  # 15 Ú©Ù„Ù…Ù‡ Ø¨Ø±ØªØ±
                density = (count / word_count) * 100
                report.append(f"- {kw}: {count} Ø¨Ø§Ø± ({density:.2f}%)")
            
            # ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹
            report.append("\nğŸ“ˆ *ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹:*")
            if len(sorted_kws) > 5:
                first_half = sum(count for _, count in sorted_kws[:len(sorted_kws)//2])
                second_half = sum(count for _, count in sorted_kws[len(sorted_kws)//2:])
                
                if first_half > second_half * 1.5:
                    report.append("âš ï¸ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù† Ø§Ø³Øª (ØªÙ…Ø±Ú©Ø² Ø¯Ø± Ù†ÛŒÙ…Ù‡ Ø§ÙˆÙ„ Ù…ØªÙ†)")
                else:
                    report.append("âœ… ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…ØªÙˆØ§Ø²Ù† Ø§Ø³Øª")
            
            return "\n".join(report)
            
        except Exception as e:
            logger.error(f"Error in keyword density analysis: {str(e)}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ú†Ú¯Ø§Ù„ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø±Ø® Ø¯Ø§Ø¯."

    @log_activity
    def analyze_readability(self, update: Update, text: str) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ø³Ø·Ø­ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ù…ØªÙ† Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
            analysis = self.ai_service.analyze_text(
                task="readability_analysis",
                text=text,
                language="fa"
            )
            
            if not analysis:
                return "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            
            # ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù†ØªÛŒØ¬Ù‡
            result = [
                f"ğŸ“š *Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ:*",
                f"ğŸ”¹ Ø§Ù…ØªÛŒØ§Ø² Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ: {analysis.get('score', 0)}/100",
                f"ğŸ”¹ Ø³Ø·Ø­ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ: {analysis.get('recommended_level', 'Ù†Ø§Ù…Ø´Ø®Øµ')}",
                f"ğŸ”¹ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ø¬Ù…Ù„Ù‡: {analysis.get('avg_sentence_length', 0)} Ú©Ù„Ù…Ù‡",
                "\nğŸ“Œ *ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯:*",
                analysis.get('suggestions', 'Ù‡ÛŒÚ† ØªÙˆØµÛŒÙ‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.')
            ]
            
            return "\n".join(result)
            
        except Exception as e:
            logger.error(f"Error in readability analysis: {str(e)}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯."

    @log_activity
    def optimize_seo(self, update: Update, text: str) -> str:
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ"""
        try:
            # ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
            optimization = self.ai_service.analyze_text(
                task="seo_optimization",
                text=text,
                language="fa"
            )
            
            if not optimization:
                return "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø¦Ùˆ. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            
            # ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù†ØªÛŒØ¬Ù‡
            result = [
                f"ğŸ” *Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø¦Ùˆ:*",
                f"ğŸ”¹ Ø§Ù…ØªÛŒØ§Ø² Ø³Ø¦Ùˆ: {optimization.get('seo_score', 0)}/100",
                "\nâœ… *Ù†Ù‚Ø§Ø· Ù‚ÙˆØª:*",
                optimization.get('strengths', 'Ù‡ÛŒÚ† Ù†Ù‚Ø·Ù‡ Ù‚ÙˆØª Ù…Ø´Ø®ØµÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.'),
                "\nâš ï¸ *Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù:*",
                optimization.get('weaknesses', 'Ù‡ÛŒÚ† Ù†Ù‚Ø·Ù‡ Ø¶Ø¹Ù Ù…Ø´Ø®ØµÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.'),
                "\nğŸ’¡ *Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯:*",
                optimization.get('recommendations', 'Ù‡ÛŒÚ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.')
            ]
            
            return "\n".join(result)
            
        except Exception as e:
            logger.error(f"Error in SEO optimization: {str(e)}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø¦Ùˆ Ø±Ø® Ø¯Ø§Ø¯."

    @log_activity
    def summarize_content(self, update: Update, text: str) -> str:
        """Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ØªÙ†"""
        try:
            # Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
            summary = self.ai_service.analyze_text(
                task="summarization",
                text=text,
                language="fa",
                params={"length": "medium"}
            )
            
            if not summary or not summary.get('summary'):
                return "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            
            # ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù†ØªÛŒØ¬Ù‡
            result = [
                f"ğŸ“ *Ø®Ù„Ø§ØµÙ‡ Ù…ØªÙ†:*",
                summary['summary'],
                f"\nğŸ“‰ *Ø¯Ø±ØµØ¯ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ: {summary.get('reduction_rate', 0)}%*"
            ]
            
            return "\n".join(result)
            
        except Exception as e:
            logger.error(f"Error in content summarization: {str(e)}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø±Ø® Ø¯Ø§Ø¯."

    @log_activity
    def check_plagiarism(self, update: Update, text: str) -> str:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ Ùˆ Ù…Ø´Ø§Ø¨Ù‡Øªâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ù…ÙˆØªÙˆØ±Ù‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ
            plagiarism_check = self.ai_service.analyze_text(
                task="plagiarism_check",
                text=text,
                language="fa"
            )
            
            if not plagiarism_check:
                return "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
            
            # ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù†ØªÛŒØ¬Ù‡
            result = [
                f"ğŸ” *Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ:*",
                f"ğŸ”¹ Ø¯Ø±ØµØ¯ Ø§ØµØ§Ù„Øª: {plagiarism_check.get('originality_score', 0)}%",
                f"ğŸ”¹ Ø¯Ø±ØµØ¯ Ù…Ø´Ø§Ø¨Ù‡Øª: {plagiarism_check.get('similarity_score', 0)}%",
            ]
            
            if plagiarism_check.get('similar_sources'):
                result.append("\nâš ï¸ *Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø´Ø§Ø¨Ù‡:*")
                for i, source in enumerate(plagiarism_check['similar_sources'][:3], 1):
                    result.append(
                        f"{i}. [{truncate_text(source.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†'), 30)}]"
                        f"({source.get('url', '#')}) - "
                        f"Ù…Ø´Ø§Ø¨Ù‡Øª: {source.get('similarity_percentage', 0)}%"
                    )
            
            return "\n".join(result)
            
        except Exception as e:
            logger.error(f"Error in plagiarism check: {str(e)}", exc_info=True)
            return "âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±Ù‚Øª Ø§Ø¯Ø¨ÛŒ Ø±Ø® Ø¯Ø§Ø¯."

    def send_analysis_result(self, update: Update, tool_name: str, result: str) -> None:
        """Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        try:
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø¨Ø¹Ø¯ÛŒ
            buttons = [
                [InlineKeyboardButton("ğŸ”„ ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯", callback_data="content_menu")],
                [get_back_button()]
            ]

            update.message.reply_text(
                text=f"*{tool_name}*\n\n{result}",
                reply_markup=InlineKeyboardMarkup(buttons),
                parse_mode=ParseMode.MARKDOWN,
                disable_web_page_preview=True
            )

            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            if db and update.effective_user:
                tool_id = next(
                    (t['id'] for t in self.TOOLS if t['name'] == tool_name), 
                    None
                )
                
                if tool_id:
                    db.save_content_analysis(
                        user_id=update.effective_user.id,
                        tool_id=tool_id,
                        input_text=truncate_text(update.message.text, 500),
                        result=truncate_text(result, 1000)
                    )
            
        except Exception as e:
            logger.error(f"Error sending analysis result: {str(e)}", exc_info=True)
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø±Ø® Ø¯Ø§Ø¯.")

    def return_to_main_menu(self, query) -> None:
        """Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§"""
        try:
            buttons = []
            
            for i in range(0, len(self.TOOLS), 2):
                row = []
                for tool in self.TOOLS[i:i+2]:
                    row.append(
                        InlineKeyboardButton(
                            text=tool['name'],
                            callback_data=f"content_{tool['id']}"
                        )
                    )
                buttons.append(row)
            
            buttons.append([get_back_button("Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ")])

            query.edit_message_text(
                text="ğŸ“ *Ù…Ù†ÙˆÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§*\n\nÙ„Ø·ÙØ§ Ø§Ø¨Ø²Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                reply_markup=InlineKeyboardMarkup(buttons),
                parse_mode=ParseMode.MARKDOWN
            )

        except Exception as e:
            logger.error(f"Error returning to main menu: {str(e)}", exc_info=True)
            query.edit_message_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ Ø±Ø® Ø¯Ø§Ø¯.")

    def send_error_message(self, update: Update, action: str) -> None:
        """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        if update.message:
            update.message.reply_text(f"âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± {action} Ø±Ø® Ø¯Ø§Ø¯.")

    def _get_persian_stopwords(self) -> List[str]:
        """Ù„ÛŒØ³Øª Ú©Ù„Ù…Ø§Øª Ø¨ÛŒâ€ŒÙ…Ø¹Ù†ÛŒ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ"""
        return [
            'Ùˆ', 'Ø¯Ø±', 'Ø¨Ù‡', 'Ø§Ø²', 'Ú©Ù‡', 'Ø±Ø§', 'Ø§ÛŒÙ†', 'Ø§Ø³Øª', 'Ø¨Ø§', 'Ø¨Ø±Ø§ÛŒ',
            'Ø¢Ù†', 'ÛŒÚ©', 'ÛŒØ§', 'Ù‡Ù…', 'Ø§Ù…Ø§', 'ØªØ§', 'Ú©Ù†ÛŒØ¯', 'Ø´Ø¯Ù‡', 'Ø´ÙˆØ¯',
            'Ù‡Ø§ÛŒ', 'Ú©Ø±Ø¯', 'Ø´Ø¯', 'Ø®ÙˆØ¯', 'Ù…Ø§', 'Ø´Ù…Ø§', 'Ø§Ùˆ', 'Ø¢Ù†Ù‡Ø§', 'Ù‡Ù…Ù‡',
            'Ù‡Ø±', 'Ø§Ú¯Ø±', 'Ù†ÛŒØ²', 'Ø¯ÛŒÚ¯Ø±', 'Ø¨Ø³ÛŒØ§Ø±', 'Ú†Ù‡', 'Ù‡Ø³ØªÙ†Ø¯', 'Ø¨ÛŒ', 'Ù…Ù†',
            'ØªÙˆ', 'Ø¨Ø±', 'Ù‡Ù…ÛŒÙ†', 'Ù‡ÛŒÚ†', 'Ø¯Ùˆ', 'Ú†ÙˆÙ†', 'Ù¾ÛŒØ´', 'Ø¨ÛŒÙ†', 'Ú†ÛŒØ³Øª',
            'Ú©Ø±Ø¯Ù†', 'Ú©Ø±Ø¯Ù…', 'Ú©Ù†Ù…', 'Ú©Ù†ÛŒ', 'Ú©Ù†Ø¯', 'Ú©Ù†ÛŒÙ…', 'Ú©Ù†ÛŒØ¯', 'Ú©Ù†Ù†Ø¯'
        ]

def setup_content_handlers(dispatcher) -> None:
    """ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§"""
    handler = ContentAnalysisHandler()
    
    dispatcher.add_handler(CommandHandler("content", handler.content_menu))
    dispatcher.add_handler(CallbackQueryHandler(
        handler.handle_content_callback, 
        pattern="^content_"
    ))
    dispatcher.add_handler(MessageHandler(
        Filters.text & ~Filters.command,
        handler.process_content_input,
        pass_user_data=True
    ))
    dispatcher.add_handler(CallbackQueryHandler(
        handler.return_to_main_menu,
        pattern="^content_menu$"
    ))
